%!TEX root = cscw2018-comic.tex

\section{Results}
\label{sec:Results}

\subsection{Raw Data}
\label{sub:Raw Data}
In this section we describe the raw data counts, the number of participants, the number of people whose responses we dropped. The final number of observations

\subsection{Bayesian Model}
\label{sub:Bayesian Model}
We use a Bayesian formulation of the problem of identifying suitable predictors for the messages in comic form.~\textcite{Kay2016} provide an nice introduction on the appropriateness of Bayesian analysis for the HCI community. Bayesian analysis is attractive in our experiment due to two advantages: shifting the conversation from ``did it work'' to ``how strong is the effect''; and benefits to small $n$ studies.

We manipulate five independent variables: gesture of the participants in the comic (3: neutral, moderate, extreme);  distance between the two characters (3:close, moderate, far); comic shading (3:white, light gray, gray); framing (2: whether the information was positively framed or negatively framed); and comic position (2: whether we presented the comic panel to the left or to the right). The last manipulation to guard against information ordering effects. This gives us a total of $3 \times 3 \times 3 \times 2 \times 2 = 54$ conditions. Thus, we need to estimate the effect on the responses for each of these variables; the responses are on a 7 point Licket scale.

A challenge with using ordinal scale such as the Lickert scale: we do not know the ``width'' of each response. That is, while we may know that for example $1<2<3$, we don't know if the difference in the thresholds used by subjects to mark ``2'' on the scale, is the same as the difference in thresholds they use for ``1'' and ``3.''  We assume that each response by a subject: lies in a continuous metric space; is Normally distributed; and that the thresholds $\{\theta_i\}$ while unknown, are sharedâ€”all subjects use same set of thresholds to identify the appropriate ordinal value.

Formally let $z$ be the response of the subjects to the experiment where the comic panel was generated by the different conditions; each condition is obtained by setting each of the $k$ independent variables $\{x_j\}, j \in [1 \ldots k]$. The subjects first generate a Normally distributed metric variable $y$, and then use the thresholds $\{\theta_i\}$ to map $y$ to the ordinal variable $z$.

Then, since we assume that the metric variable $y$ is Normally distributed, our hierarchical Bayesian model is defined as follows (see~\Cref{fig:generative-main} for a graphical representation):

\begin{align}
 y                  & \sim N(\mu, \sigma_y)                    \label{eq:response-main}                     \\
 \sigma_y           & \sim U(L, H), \label{eq:main-sigma}                                                   \\
 \mu                & \sim \beta_0 +
 \underbrace{\sum_{j} \beta_{1,j} x_{1,j}(i)}_{\text{gesture}} +
 \underbrace{\sum_k \beta_{2,k} x_{1,k}(i)}_{\text{shading}} +
 \underbrace{\sum_l \beta_{3,l} x_{1,l}(i)}_{\text{distance}} +
 \underbrace{\sum_m \beta_{4,m} x_{1,m}(i)}_{\text{framing}} +
 \underbrace{\sum_n \beta_{5,n} x_{1,n}(i)}_{\text{comic position}},                  \label{eq:mu-main} \\
 \sum_j \beta_{k,j} & = 0, \qquad k \in \{1, \ldots, 5\}, \label{eq:beta-equality}                          \\
 \beta_{i,j}        & \sim N(0, \sigma_{\beta, i}), \quad i \in \{1, \ldots, 5\},\label{eq:main-beta-sigma} \\
 \sigma_{\beta, i}  & \sim \Gamma(s, r ). \label{eq:gamma-distribution}
\end{align}
\Cref{eq:response-main} says that the metric variable $y$ is Normally distributed\footnote{The ``$\sim$'' symbol means that the random variable on the left is drawn from the probability distribution on the right.} with mean $\mu$ and standard deviation $\sigma_y$.~\Cref{eq:mu-main} says that the mean response $\mu$ is a linear weighted combination of the predictors.~\Cref{eq:main-sigma} says that the standard deviation of the response is drawn from a Uniform distribution with constant parameters $\text{Low}=L, \text{High}=H$, where $L>0, H\gg L$.~\Cref{eq:main-beta-sigma} says that the predictor weight is drawn from a Normal distribution with $\mu=0$ and standard deviation $\sigma_{\beta, i}$. That is,  while \textit{each} predictor set $\beta_{i}$ is drawn from a \textit{different} Normal distribution, the $\beta{i,j}$ values within the same predictor set $\beta_{i}$ are drawn from the \textit{same} Normal distribution.~\Cref{eq:beta-equality} says that the sum of the deflections $\sum_k \beta_{j,k}$ from the mean for any nominal predictor $j$ equals zero.~\Cref{eq:gamma-distribution} says that we draw all the variances $\sigma_{\beta, i}$ from the same Gamma $\Gamma(s,r)$ distribution, where $s$ refers to the shape parameter and $r$ refers to the rate parameter. We set the variables $s,r$ to allows a wide range of values for $\sigma_{\beta, i}$. By drawing the standard deviation variables $\sigma_{\beta, i}$ from the same Gamma distribution, the values of each $\beta_i$ informs the other values. This ``information sharing'' among variables is common to hierarchical Bayesian models and is an important reason why Bayesian models work so well with small datasets\footnote{The sharing of information causes each of the $\sigma_{\beta, i}$, to move towards the group mean, a phenomena known as ``shrinkage.'' }. The main advantage of using a Gamma distribution is that we can specify a non-zero mode, important in controlling shrinkage in hierarchical models.

\begin{figure}
 \includegraphics[width=\textwidth]{./figures/generative_model_main.pdf}
 \caption{The figure shows the hierarchical Bayesian model specification, corresponding to~\Crefrange{eq:response-main}{eq:gamma-distribution}.}
 \label{fig:generative-main}
\end{figure}

Thus far, we have discussed how to generate a Normally distributed response variable $r$. However, what we see in the experiment is not this response variable, but an ordinal variable. The subjects use internal thresholds $\{\theta_i\}$ to determine when to indicate ``strongly disagree'', ``disagree'' etc. Thus with a 7 point Likert scale, we have 6 thresholds. The probability that we will see an ordinal response $y=k$ is $P(y=k | \mu, \sigma, \{\theta_i\})$, where, $\{\theta_i\}$ is the set of thresholds used by the subjects. We assume that while these thresholds are unknown, all subjects use the same thresholds. Since the response $r$ is Normally distributed, we can compute the probabilities as follows:

\begin{equation}
 P(y=k | \mu, \sigma, \{\theta_i\}) = \Phi \left (\frac{\theta_k - \mu}{\sigma} \right) - \Phi \left(\frac{\theta_{k-1} - \mu}{\sigma} \right).
\end{equation}
Where, $\Phi$ represents the cumulative density function for the Normal distribution. In other words, the probability that we will see ordinal response $k$ is the area under the Normal distribution with parameters $\mu, \sigma$ between thresholds $\theta_{k-1}$ and $\theta_k$.

The thresholds $\theta_i, i \in [1, \ldots, k]$ have two degrees of freedom in that a simple translation of the response will translate the thresholds. Consistent with~\textcite[][p. 674]{Kruschke2014}, we set $\theta_1\equiv1.5$ and $\theta_6\equiv6.5$, leaving us with four hidden threshold parameters. We specify these parameters as follows:
\begin{equation}
 \theta_i \sim N(i+0.5, 1/2), i \in [2, 3, 4, 5].
\end{equation}

\subsection{Analysis}
\label{sub:Analysis}

We analyzed the data using PyMC3~\cite{Salvatier2016}, a popular framework for Bayesian inference. Computational techniques for Bayesian inference use a stochastic sampling technique called Markov Chain Monte Carlo (MCMC) that samples the posterior distribution $P(\theta | D)$, where we want to estimate the parameters $\theta$ given the observations $D$. In particular, we used the Metropolis-Hastings sampler. The Gelman-Rubin statistic $\hat{R}$ was around 1, indicating that the different sampling chains converged. The modal values of the coefficients are as follows:

\begin{table}[htb]%\footnotesize
 \centering
 \caption{Modal coefficient values $\beta_{0-5}$. Some coefficients are vectors as they represent the displacement from the mean for different conditions of that variable. For example, since gesture has three experimental conditions, $\beta_1$ is a vector of length 3.}\label{tab:modal values}
 \begin{tabular}{@{}rl@{}} \toprule
  Coefficient                     & Values                     \\ \midrule
  Intercept ($\beta_0$)           & $4.524$                    \\
  Gesture ($\beta_1$)             & $[-0.218, 0.101, 0.118]$   \\
  Shading ($\beta_2$)             & $ [-0.218 , 0.101, 0.118]$ \\
  Distance ($\beta_3$)            & $[-0.043, -0.057, 0.099]$  \\
  Framing ($\beta_4$)             & $[ 0.05, -0.051]$          \\
  Comic Position ($\beta_5$)      & $[0, 0]$                   \\
  Standard Deviation ($\sigma_y$) & $1.614$                    \\ \bottomrule
 \end{tabular}
\end{table}


\begin{figure}
 \subfloat[The mean effect and the effect size\label{subfig-1:mean-effect}]{%
  \includegraphics[width=0.6\textwidth]{./hari-code/factors_mean_effect_main-noint.pdf}
  } \hfill
 \subfloat[Information framing contrast\label{subfig-2:framing}]{%
  \includegraphics[width=0.33\textwidth]{./hari-code/factors_framing_contrasts_main-noint.pdf}
 }
 \caption{~\Cref{subfig-1:mean-effect} showsHigh Posterior Density (HPD) intervals for the mean response $\mu$ and effect sizes $\sigma_y$. HPD represent the region with 95\% of the density. Notice that the HPD interval for $\mu$ is $[4.35, 4.70]$ and excludes 4 (the neutral response value), implying that on average, the response to the comic panel was more persuasive than the text. The figure for effect size shows a moderate effect with mode $0.33$; since the HPD interval $[0.21, 0.44]$ excludes 0, we can be confident about the effect.~\Cref{subfig-2:framing} shows the contrasts between negatively framed message with a positively framed message. The modal value is $0.08$, but since the HPD interval $[-0.12, 0.36]$ overlaps with 0, there is no appreciable effect (interestingly 80\% of the density lies in the region greater than 0.)}
 \label{fig:main-experiment-effect}
\end{figure}

\begin{figure}
 \includegraphics[width=\textwidth]{./hari-code/factors_gesture_contrasts_main-noint.pdf}
 \caption{gesture contrasts}
 \label{fig:gesture-contrasts-main}
\end{figure}

\begin{figure}
 \includegraphics[width=\textwidth]{./hari-code/factors_shading_contrasts_main-noint.pdf}
 \caption{shading contrasts}
 \label{fig:shading-contrasts-main}
\end{figure}

\begin{figure}
 \includegraphics[width=\textwidth]{./hari-code/factors_distance_contrasts_main-noint.pdf}
 \caption{distance contrasts}
 \label{fig:distance-contrasts-main}
\end{figure}
